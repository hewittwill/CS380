{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS380 UNet\n",
    "\n",
    "**Author:** Will Hewitt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "Trains UNet for segmenting echocardiography images\n",
    "\n",
    "### Conda Environment\n",
    "\n",
    "`conda activate heartlab`\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "`/data/camus/v5/{x_train/test/val | y_train/test/val}.npy`\n",
    "\n",
    "### References\n",
    "\n",
    "CS380-Prepare-Data.ipynb, CS380-UNet-Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, Concatenate\n",
    "\n",
    "sys.path.append('../segmentation_utils')\n",
    "\n",
    "from segmentation_utils import jaccard_distance_loss, dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/srv/jupyterhub_notebooks/data/camus/v5/\"\n",
    "\n",
    "x_train, x_val = np.load(path + 'x_train.npy'), np.load(path + 'x_val.npy')\n",
    "y_train, y_val = np.load(path + 'y_train.npy'), np.load(path + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperparameters\n",
    "\n",
    "Make sure to recompile the whole model after changing these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_dropout_thresh = 0.5\n",
    "adam_optimizer = Adam(learning_rate=1e-5)\n",
    "freeze_encoder_weights = False # If True, encoder weights ARE frozen. If False, encoder weights ARE NOT frozen.\n",
    "n_epochs=50\n",
    "batch_size=16\n",
    "loss_function='categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(256,256,1))\n",
    "input_concat = Concatenate()([input_layer, input_layer, input_layer])\n",
    "\n",
    "encoder_model = VGG16(input_tensor=input_concat, include_top=False, weights='imagenet', pooling=None)\n",
    "\n",
    "# Cut off the last conv block\n",
    "\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder_model.get_layer(\"block4_pool\").output)\n",
    "\n",
    "# Set weights frozen\n",
    "\n",
    "for layer in encoder_model.layers:\n",
    "    layer.trainable = !freeze_encoder_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Build Bottleneck and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottleneck\n",
    "\n",
    "bottleneck1_1 = Dropout(bottleneck_dropout_thresh)(Conv2D(1024, (3,3), activation='relu', padding='same')(encoder_model.output))\n",
    "bottleneck1_2 = Dropout(bottleneck_dropout_thresh)(Conv2D(1024, (3,3), activation='relu', padding='same')(bottleneck1_1))\n",
    "\n",
    "# up block 1\n",
    "\n",
    "upconv1_1 = Conv2DTranspose(512, 2, (2,2), padding='same', activation='relu')(bottleneck1_2)\n",
    "upconv1_2 = Concatenate(axis=3)(inputs=[upconv1_1, encoder_model.get_layer(name='block4_conv3').output])\n",
    "upconv1_3 = Conv2D(512, (3,3), activation='relu', padding='same')(upconv1_2)\n",
    "upconv1_4 = Conv2D(512, (3,3), activation='relu', padding='same')(upconv1_3)\n",
    "\n",
    "# up block 2\n",
    "\n",
    "upconv2_1 = Conv2DTranspose(256, 2, (2,2), padding='same', activation='relu')(upconv1_4)\n",
    "upconv2_2 = Concatenate(axis=3)(inputs=[upconv2_1, encoder_model.get_layer(name='block3_conv3').output])\n",
    "upconv2_3 = Conv2D(256, (3,3), activation='relu', padding='same')(upconv2_2)\n",
    "upconv2_4 = Conv2D(256, (3,3), activation='relu', padding='same')(upconv2_3)\n",
    "\n",
    "# up block 3\n",
    "\n",
    "upconv3_1 = Conv2DTranspose(128, 2, (2,2), padding='same', activation='relu')(upconv2_4)\n",
    "upconv3_2 = Concatenate(axis=3)(inputs=[upconv3_1, encoder_model.get_layer(name='block2_conv2').output])\n",
    "upconv3_3 = Conv2D(128, (3,3), activation='relu', padding='same')(upconv3_2)\n",
    "upconv3_4 = Conv2D(128, (3,3), activation='relu', padding='same')(upconv3_3)\n",
    "\n",
    "# up block 4\n",
    "\n",
    "upconv4_1 = Conv2DTranspose(64, 2, (2,2), padding='same', activation='relu')(upconv3_4)\n",
    "upconv4_2 = Concatenate(axis=3)(inputs=[upconv4_1, encoder_model.get_layer(name='block1_conv2').output])\n",
    "upconv4_3 = Conv2D(64, (3,3), activation='relu', padding='same')(upconv4_2)\n",
    "upconv4_4 = Conv2D(64, (3,3), activation='relu', padding='same')(upconv4_3)\n",
    "\n",
    "# output layer\n",
    "output_layer = Conv2D(4, (1,1), activation='softmax')(upconv4_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setup TensorBoard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + run_name\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compile final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, \n",
    "              loss=loss_function, \n",
    "              metrics=[MeanIoU(num_classes=4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 90 samples\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 28s 39ms/sample - loss: 1.3378 - mean_io_u: 0.3750 - val_loss: 0.8280 - val_mean_io_u: 0.3750\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.7036 - mean_io_u: 0.3750 - val_loss: 0.5582 - val_mean_io_u: 0.3751\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.4892 - mean_io_u: 0.3755 - val_loss: 0.4343 - val_mean_io_u: 0.3758\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.4038 - mean_io_u: 0.3773 - val_loss: 0.3756 - val_mean_io_u: 0.3763\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.3417 - mean_io_u: 0.3801 - val_loss: 0.3115 - val_mean_io_u: 0.3778\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.2888 - mean_io_u: 0.3856 - val_loss: 0.3201 - val_mean_io_u: 0.3780\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.2435 - mean_io_u: 0.3903 - val_loss: 0.2314 - val_mean_io_u: 0.3873\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.2054 - mean_io_u: 0.4045 - val_loss: 0.2259 - val_mean_io_u: 0.4261\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.1855 - mean_io_u: 0.4143 - val_loss: 0.2513 - val_mean_io_u: 0.4103\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.1742 - mean_io_u: 0.4169 - val_loss: 0.2164 - val_mean_io_u: 0.3913\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.1626 - mean_io_u: 0.4199 - val_loss: 0.1883 - val_mean_io_u: 0.4167\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.1569 - mean_io_u: 0.4271 - val_loss: 0.1904 - val_mean_io_u: 0.3939\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1481 - mean_io_u: 0.4275 - val_loss: 0.1810 - val_mean_io_u: 0.4161\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.1438 - mean_io_u: 0.4306 - val_loss: 0.1905 - val_mean_io_u: 0.4021\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1399 - mean_io_u: 0.4284 - val_loss: 0.1658 - val_mean_io_u: 0.4227\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1341 - mean_io_u: 0.4388 - val_loss: 0.1787 - val_mean_io_u: 0.4123\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 20s 27ms/sample - loss: 0.1311 - mean_io_u: 0.4398 - val_loss: 0.1671 - val_mean_io_u: 0.4283\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1278 - mean_io_u: 0.4407 - val_loss: 0.1999 - val_mean_io_u: 0.4261\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1252 - mean_io_u: 0.4439 - val_loss: 0.1557 - val_mean_io_u: 0.4280\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1250 - mean_io_u: 0.4433 - val_loss: 0.1772 - val_mean_io_u: 0.4339\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1198 - mean_io_u: 0.4450 - val_loss: 0.1854 - val_mean_io_u: 0.4372\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1171 - mean_io_u: 0.4488 - val_loss: 0.1606 - val_mean_io_u: 0.4570\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1159 - mean_io_u: 0.4546 - val_loss: 0.2004 - val_mean_io_u: 0.4286\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1140 - mean_io_u: 0.4541 - val_loss: 0.1679 - val_mean_io_u: 0.4294\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1126 - mean_io_u: 0.4490 - val_loss: 0.1841 - val_mean_io_u: 0.4400\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1102 - mean_io_u: 0.4558 - val_loss: 0.1595 - val_mean_io_u: 0.4408\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1092 - mean_io_u: 0.4517 - val_loss: 0.1737 - val_mean_io_u: 0.4439\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1100 - mean_io_u: 0.4573 - val_loss: 0.1462 - val_mean_io_u: 0.4453\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1071 - mean_io_u: 0.4547 - val_loss: 0.1465 - val_mean_io_u: 0.4480\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1048 - mean_io_u: 0.4534 - val_loss: 0.1555 - val_mean_io_u: 0.4475\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1032 - mean_io_u: 0.4640 - val_loss: 0.1541 - val_mean_io_u: 0.4439\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1013 - mean_io_u: 0.4583 - val_loss: 0.1771 - val_mean_io_u: 0.4363\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0987 - mean_io_u: 0.4645 - val_loss: 0.2240 - val_mean_io_u: 0.4422\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.1001 - mean_io_u: 0.4609 - val_loss: 0.1528 - val_mean_io_u: 0.4558\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0980 - mean_io_u: 0.4621 - val_loss: 0.1440 - val_mean_io_u: 0.4559\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0982 - mean_io_u: 0.4642 - val_loss: 0.1633 - val_mean_io_u: 0.4472\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0950 - mean_io_u: 0.4618 - val_loss: 0.1700 - val_mean_io_u: 0.4548\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0940 - mean_io_u: 0.4621 - val_loss: 0.1715 - val_mean_io_u: 0.4546\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0928 - mean_io_u: 0.4660 - val_loss: 0.1799 - val_mean_io_u: 0.4536\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0915 - mean_io_u: 0.4679 - val_loss: 0.1934 - val_mean_io_u: 0.4469\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0907 - mean_io_u: 0.4645 - val_loss: 0.1809 - val_mean_io_u: 0.4503\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0907 - mean_io_u: 0.4674 - val_loss: 0.1725 - val_mean_io_u: 0.4555\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0901 - mean_io_u: 0.4639 - val_loss: 0.1893 - val_mean_io_u: 0.4520\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0874 - mean_io_u: 0.4660 - val_loss: 0.1752 - val_mean_io_u: 0.4451\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0853 - mean_io_u: 0.4677 - val_loss: 0.1907 - val_mean_io_u: 0.4578\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0857 - mean_io_u: 0.4719 - val_loss: 0.1841 - val_mean_io_u: 0.4531\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0852 - mean_io_u: 0.4717 - val_loss: 0.2665 - val_mean_io_u: 0.4338\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0875 - mean_io_u: 0.4607 - val_loss: 0.1416 - val_mean_io_u: 0.4574\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0835 - mean_io_u: 0.4638 - val_loss: 0.1734 - val_mean_io_u: 0.4505\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 20s 28ms/sample - loss: 0.0806 - mean_io_u: 0.4717 - val_loss: 0.2048 - val_mean_io_u: 0.4448\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "model.save('models/' + run_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:heartlab]",
   "language": "python",
   "name": "conda-env-heartlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
